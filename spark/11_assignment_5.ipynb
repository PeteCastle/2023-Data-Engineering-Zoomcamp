{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark  \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, StringType, IntegerType, TimestampType\n",
    "import os\n",
    "import pyspark.sql.functions as F\n",
    "import json\n",
    "import glob\n",
    "\n",
    "credentials = json.load(open(\"../credentials/credentials.json\"))\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .master(\"spark://localhost:7077\")\\\n",
    "    .appName('HelloWorld')\\\n",
    "    .config(\"spark.driver.memory\", \"6G\") \\\n",
    "    .config(\"spark.executor.memory\", \"6G\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"6G\") \\\n",
    "    .config(\"fs.azure\", \"org.apache.hadoop.fs.azure.NativeAzureFileSystem\")\\\n",
    "    .config(f'fs.azure.account.key.{credentials[\"storage_account_name\"]}.blob.core.windows.net',credentials[\"storage_account_key\"])\\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://FrancisMark.local:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://localhost:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>HelloWorld</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2a3eaebdc90>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark\n",
    "# print(\"Spark Version: \", spark.version)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and downloading HVFHW data 2021 file.\n",
    "Download is managed by prefect orion client.\n",
    "\n",
    "~~`prefect orion start`~~\n",
    "\n",
    "~~`prefect agent start 'default'` ~~\n",
    "\n",
    "~~Deployment `etl-local-flow` is run with parameters `{\"year\":[2021],\"month\":[6]},\"color\":[\"fhvhv\"]}`~~\n",
    "\n",
    "**NOTE: The data from the CSV coming from Github repository is different from the website**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: string (nullable = true)\n",
      " |-- dropoff_datetime: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fvhv = spark.read.csv(\"../resources/datasets/fhvhv/2021/06\",header=True, inferSchema=True,)\n",
    "df_fvhv.printSchema()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fvhv_schema = \\\n",
    "    StructType(\n",
    "        [\n",
    "            StructField(\"dispatching_base_num\",StringType(),True),\n",
    "            StructField(\"pickup_datetime\",TimestampType(),True),\n",
    "            StructField(\"dropoff_datetime\",TimestampType(),True),\n",
    "            StructField(\"PULocationID\",IntegerType(),True),\n",
    "            StructField(\"DOLocationID\",IntegerType(),True),\n",
    "            StructField(\"SR_Flag\",StringType(),True),\n",
    "            StructField(\"Affiliated_base_number\",StringType(),True)\n",
    "        ])\n",
    "df_fvhv = spark.read.csv(\"../resources/datasets/fhvhv/2021/06\",header=True, schema=df_fvhv_schema)\n",
    "df_fvhv.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|    pickup_datetime|   dropoff_datetime|\n",
      "+-------------------+-------------------+\n",
      "|2021-06-01 00:02:41|2021-06-01 00:07:46|\n",
      "|2021-06-01 00:16:16|2021-06-01 00:21:14|\n",
      "|2021-06-01 00:27:01|2021-06-01 00:42:11|\n",
      "|2021-06-01 00:46:08|2021-06-01 00:53:45|\n",
      "|2021-06-01 00:45:42|2021-06-01 01:03:33|\n",
      "+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fvhv.select([\"pickup_datetime\",\"dropoff_datetime\"]).show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Repartition into 12 partitions and save to parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average file size is: 23066452.333333332 bytes\n"
     ]
    }
   ],
   "source": [
    "file_loc = \"../resources/datasets/fhvhv_2021_06_partitioned\"\n",
    "\n",
    "df_fvhv.repartition(12).write.option(\"header\", \"true\").parquet(f\"{file_loc}\")\n",
    "\n",
    "parquet_files = glob.glob(os.path.join(file_loc, \"*.parquet\"))\n",
    "\n",
    "total_size = 0\n",
    "for file_path in parquet_files:\n",
    "    total_size += os.path.getsize(file_path)\n",
    "print(f\"Average file size is: {total_size/len(parquet_files)} bytes\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "How many taxi trips were there on June 15?</br>\n",
    "Consider only trips that started on June 15.</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of taxi trips on 15th June 2021: 452470\n"
     ]
    }
   ],
   "source": [
    "taxi_trips_count = df_fvhv.where(\"DAY(pickup_datetime) == 15\").count()\n",
    "print(f\"Number of taxi trips on 15th June 2021: {taxi_trips_count}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "Now calculate the duration for each trip.</br>\n",
    "How long was the longest trip in Hours?</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|trip_duration_hours|\n",
      "+-------------------+\n",
      "| INTERVAL '66' HOUR|\n",
      "| INTERVAL '25' HOUR|\n",
      "| INTERVAL '19' HOUR|\n",
      "| INTERVAL '18' HOUR|\n",
      "| INTERVAL '16' HOUR|\n",
      "+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fvhv.createOrReplaceTempView(\"df_fvhv\")\n",
    "trip_durations = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        CAST(dropoff_datetime - pickup_datetime AS INTERVAL HOUR) AS trip_duration_hours\n",
    "    FROM\n",
    "        df_fvhv\n",
    "    ORDER BY\n",
    "        trip_duration_hours DESC\n",
    "\"\"\"\n",
    ")\n",
    "trip_durations.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root\n",
    " |-- dispatching_base_num: string (nullable = true)\n",
    " |-- pickup_datetime: timestamp (nullable = true)\n",
    " |-- dropoff_datetime: timestamp (nullable = true)\n",
    " |-- PULocationID: integer (nullable = true)\n",
    " |-- DOLocationID: integer (nullable = true)\n",
    " |-- SR_Flag: string (nullable = true)\n",
    " |-- Affiliated_base_number: string (nullable = true)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "Load the zone lookup data into a temp view in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_zone_lookpup = spark.read.csv(\"../resources/datasets/taxi+_zone_lookup.csv\",header=True, inferSchema=True)\n",
    "taxi_zone_lookpup.show(5)\n",
    "taxi_zone_lookpup.createOrReplaceTempView(\"taxi_zone_lookpup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- pickup_borough: string (nullable = true)\n",
      " |-- pickup_zone: string (nullable = true)\n",
      " |-- dropoff_borough: string (nullable = true)\n",
      " |-- dropoff_zone: string (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fvhv_full = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        df_fvhv.dispatching_base_num,\n",
    "        df_fvhv.pickup_datetime,\n",
    "        df_fvhv.dropoff_datetime,\n",
    "        pickup_zone.Borough AS pickup_borough,\n",
    "        pickup_zone.Zone AS pickup_zone,\n",
    "        dropoff_zone.Borough AS dropoff_borough,\n",
    "        dropoff_zone.Zone AS dropoff_zone,\n",
    "        df_fvhv.SR_Flag,\n",
    "        df_fvhv.Affiliated_base_number\n",
    "    FROM df_fvhv\n",
    "    INNER JOIN taxi_zone_lookpup AS pickup_zone\n",
    "        ON pickup_zone.LocationID = df_fvhv.PULocationID\n",
    "    INNER JOIN taxi_zone_lookpup AS dropoff_zone\n",
    "        ON dropoff_zone.LocationID = df_fvhv.DOLocationID\n",
    "\"\"\")   \n",
    "\n",
    "df_fvhv_full.printSchema()\n",
    "df_fvhv_full.createOrReplaceTempView(\"df_fvhv_full\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the zone lookup data and the fhvhv June 2021 data, what is the name of the most frequent pickup location zone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+\n",
      "|        pickup_zone|count(pickup_zone)|\n",
      "+-------------------+------------------+\n",
      "|Crown Heights North|            231279|\n",
      "|       East Village|            221244|\n",
      "|        JFK Airport|            188867|\n",
      "|     Bushwick South|            187929|\n",
      "|      East New York|            186780|\n",
      "+-------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        pickup_zone, \n",
    "        COUNT(pickup_zone)\n",
    "    FROM \n",
    "        df_fvhv_full\n",
    "    GROUP BY pickup_zone\n",
    "    ORDER BY COUNT(pickup_zone) DESC\n",
    "\"\"\").show(5)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
